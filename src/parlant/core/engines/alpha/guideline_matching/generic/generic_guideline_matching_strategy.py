# Copyright 2025 Emcie Co Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from collections import defaultdict
from datetime import datetime
from itertools import chain
import math
from typing import Mapping, Optional, Sequence, cast
from typing_extensions import override

from parlant.core import async_utils
from parlant.core.common import JSONSerializable, generate_id
from parlant.core.engines.alpha.guideline_matching.generic.common import internal_representation
from parlant.core.engines.alpha.guideline_matching.generic.disambiguation_batch import (
    DisambiguationGuidelineMatchesSchema,
    GenericDisambiguationGuidelineMatchingBatch,
)
from parlant.core.engines.alpha.guideline_matching.generic.guideline_actionable_batch import (
    GenericActionableGuidelineMatchesSchema,
    GenericActionableGuidelineMatchingBatch,
)
from parlant.core.engines.alpha.guideline_matching.generic.guideline_previously_applied_actionable_batch import (
    GenericPreviouslyAppliedActionableGuidelineMatchesSchema,
    GenericPreviouslyAppliedActionableGuidelineMatchingBatch,
)
from parlant.core.engines.alpha.guideline_matching.generic.guideline_previously_applied_actionable_customer_dependent_batch import (
    GenericPreviouslyAppliedActionableCustomerDependentGuidelineMatchesSchema,
    GenericPreviouslyAppliedActionableCustomerDependentGuidelineMatchingBatch,
)
from parlant.core.engines.alpha.guideline_matching.generic.journey_node_selection_batch import (
    GenericJourneyNodeSelectionBatch,
    JourneyNodeSelectionSchema,
)
from parlant.core.engines.alpha.guideline_matching.generic.observational_batch import (
    GenericObservationalGuidelineMatchesSchema,
    GenericObservationalGuidelineMatchingBatch,
)
from parlant.core.engines.alpha.guideline_matching.generic.response_analysis_batch import (
    GenericResponseAnalysisBatch,
    GenericResponseAnalysisSchema,
)
from parlant.core.engines.alpha.guideline_matching.guideline_match import GuidelineMatch
from parlant.core.engines.alpha.guideline_matching.guideline_matcher import (
    GuidelineMatchingBatch,
    GuidelineMatchingStrategy,
    GuidelineMatchingContext,
    ResponseAnalysisContext,
)
from parlant.core.engines.alpha.optimization_policy import OptimizationPolicy
from parlant.core.entity_cq import EntityQueries
from parlant.core.guidelines import Guideline, GuidelineContent, GuidelineId, GuidelineStore
from parlant.core.journeys import Journey, JourneyId, JourneyStore
from parlant.core.loggers import Logger
from parlant.core.nlp.generation import SchematicGenerator
from parlant.core.relationships import RelationshipKind, RelationshipStore


class GenericGuidelineMatchingStrategy(GuidelineMatchingStrategy):
    def __init__(
        self,
        logger: Logger,
        optimization_policy: OptimizationPolicy,
        guideline_store: GuidelineStore,
        journey_store: JourneyStore,
        relationship_store: RelationshipStore,
        entity_queries: EntityQueries,
        observational_guideline_schematic_generator: SchematicGenerator[
            GenericObservationalGuidelineMatchesSchema
        ],
        previously_applied_actionable_guideline_schematic_generator: SchematicGenerator[
            GenericPreviouslyAppliedActionableGuidelineMatchesSchema
        ],
        previously_applied_actionable_customer_dependent_guideline_schematic_generator: SchematicGenerator[
            GenericPreviouslyAppliedActionableCustomerDependentGuidelineMatchesSchema
        ],
        actionable_guideline_schematic_generator: SchematicGenerator[
            GenericActionableGuidelineMatchesSchema
        ],
        disambiguation_guidelines_schematic_generator: SchematicGenerator[
            DisambiguationGuidelineMatchesSchema
        ],
        journey_step_selection_schematic_generator: SchematicGenerator[JourneyNodeSelectionSchema],
        response_analysis_schematic_generator: SchematicGenerator[GenericResponseAnalysisSchema],
    ) -> None:
        self._logger = logger

        self._guideline_store = guideline_store
        self._journey_store = journey_store
        self._relationship_store = relationship_store

        self._optimization_policy = optimization_policy
        self._entity_queries = entity_queries

        self._observational_guideline_schematic_generator = (
            observational_guideline_schematic_generator
        )
        self._actionable_guideline_schematic_generator = actionable_guideline_schematic_generator
        self._previously_applied_actionable_guideline_schematic_generator = (
            previously_applied_actionable_guideline_schematic_generator
        )
        self._previously_applied_actionable_customer_dependent_guideline_schematic_generator = (
            previously_applied_actionable_customer_dependent_guideline_schematic_generator
        )
        self._disambiguation_guidelines_schematic_generator = (
            disambiguation_guidelines_schematic_generator
        )
        self._journey_step_selection_schematic_generator = (
            journey_step_selection_schematic_generator
        )
        self._response_analysis_schematic_generator = response_analysis_schematic_generator
        self._current_context: GuidelineMatchingContext | None = None

    @override
    async def create_matching_batches(
        self,
        guidelines: Sequence[Guideline],
        context: GuidelineMatchingContext,
    ) -> Sequence[GuidelineMatchingBatch]:
        self._current_context = context
        observational_guidelines: list[Guideline] = []
        previously_applied_actionable_guidelines: list[Guideline] = []
        previously_applied_actionable_customer_dependent_guidelines: list[Guideline] = []
        actionable_guidelines: list[Guideline] = []
        disambiguation_groups: list[tuple[Guideline, list[Guideline]]] = []
        journey_step_selection_journeys: dict[Journey, list[Guideline]] = defaultdict(list)

        active_journeys_mapping = {journey.id: journey for journey in context.active_journeys}

        for g in guidelines:
            if g.metadata.get("journey_node") is not None:
                # If the guideline is associated with a journey node, we add the journey steps
                # to the list of journeys that need reevaluation.
                if journey_id := cast(
                    Mapping[str, JSONSerializable], g.metadata.get("journey_node", {})
                ).get("journey_id"):
                    journey_id = cast(JourneyId, journey_id)

                    if journey_id in active_journeys_mapping:
                        journey_step_selection_journeys[active_journeys_mapping[journey_id]].append(
                            g
                        )

            elif not g.content.action:
                if targets := await self._try_get_disambiguation_group_targets(g, guidelines):
                    disambiguation_groups.append((g, targets))
                else:
                    observational_guidelines.append(g)
            else:
                if g.metadata.get("continuous", False):
                    actionable_guidelines.append(g)
                else:
                    if (
                        context.session.agent_states
                        and g.id in context.session.agent_states[-1].applied_guideline_ids
                    ):
                        data = g.metadata.get("customer_dependent_action_data", False)
                        if isinstance(data, Mapping) and data.get("is_customer_dependent", False):
                            previously_applied_actionable_customer_dependent_guidelines.append(g)
                        else:
                            previously_applied_actionable_guidelines.append(g)
                    else:
                        actionable_guidelines.append(g)

        guideline_batches: list[GuidelineMatchingBatch] = []
        if observational_guidelines:
            guideline_batches.extend(
                self._create_batches_observational_guideline(observational_guidelines, context)
            )
        if previously_applied_actionable_guidelines:
            guideline_batches.extend(
                self._create_batches_previously_applied_actionable_guideline(
                    previously_applied_actionable_guidelines, context
                )
            )
        if previously_applied_actionable_customer_dependent_guidelines:
            guideline_batches.extend(
                self._create_batches_previously_applied_actionable_customer_dependent_guideline(
                    previously_applied_actionable_customer_dependent_guidelines, context
                )
            )
        if actionable_guidelines:
            guideline_batches.extend(
                self._create_batches_actionable_guideline(actionable_guidelines, context)
            )
        if disambiguation_groups:
            guideline_batches.extend(
                [
                    self._create_batch_disambiguation_guideline(source, targets, context)
                    for source, targets in disambiguation_groups
                ]
            )
        if journey_step_selection_journeys:
            guideline_batches.extend(
                await async_utils.safe_gather(
                    *[
                        self._create_batch_journey_step_selection(examined_journey, steps, context)
                        for examined_journey, steps in journey_step_selection_journeys.items()
                    ]
                )
            )

        return guideline_batches

    @override
    async def create_response_analysis_batches(
        self,
        guideline_matches: Sequence[GuidelineMatch],
        context: ResponseAnalysisContext,
    ) -> Sequence[GenericResponseAnalysisBatch]:
        if not guideline_matches:
            return []

        return [
            GenericResponseAnalysisBatch(
                logger=self._logger,
                optimization_policy=self._optimization_policy,
                schematic_generator=self._response_analysis_schematic_generator,
                context=context,
                guideline_matches=guideline_matches,
            )
        ]

    @override
    async def transform_matches(
        self,
        matches: Sequence[GuidelineMatch],
    ) -> Sequence[GuidelineMatch]:
        result: list[GuidelineMatch] = []
        guidelines_to_skip: set[GuidelineId] = set()

        for m in matches:
            if disambiguation := m.metadata.get("disambiguation"):
                # éœ€è¦æ¾„æ¸…ï¼šæ·»åŠ clarification guidelineï¼Œæ’é™¤å†²çªçš„guidelines
                guidelines_to_skip.update(
                    cast(
                        list[GuidelineId],
                        cast(dict[str, JSONSerializable], disambiguation).get("targets"),
                    )
                )
                guidelines_to_skip.add(m.guideline.id)
                result.append(
                    GuidelineMatch(
                        guideline=Guideline(
                            id=cast(GuidelineId, f"<transient_{generate_id()}>"),
                            creation_utc=datetime.now(),
                            content=GuidelineContent(
                                condition=internal_representation(m.guideline).condition,
                                action=cast(
                                    str,
                                    cast(dict[str, JSONSerializable], disambiguation)[
                                        "enriched_action"
                                    ],
                                ),
                            ),
                            enabled=True,
                            tags=[],
                            metadata={},
                        ),
                        score=10,
                        rationale=m.rationale,
                        metadata=m.metadata,
                    )
                )

        # æ”¶é›†æ¿€æ´»çš„ Journey å…¥å£ï¼ˆå†²çªæ£€æµ‹åªåœ¨å…¥å£çº§åˆ«è¿›è¡Œï¼‰
        # journey nodes ä¸å‚ä¸å†²çªæ£€æµ‹ï¼Œå®ƒä»¬æ˜¯æ‰§è¡Œå±‚ï¼Œåœ¨å…¥å£ç¡®å®šåæ‰å¤„ç†
        journey_entries: dict[str, GuidelineMatch] = {}  # journey_id -> å…¥å£ match
        
        for m in matches:
            if m.guideline.id in guidelines_to_skip:
                continue
            for tag in m.guideline.tags:
                if tag.startswith("journey:") and m.score >= 10:
                    journey_id = tag[8:]
                    # ä¿ç•™æœ€é«˜åˆ†çš„å…¥å£ guideline
                    if journey_id not in journey_entries or m.score > journey_entries[journey_id].score:
                        journey_entries[journey_id] = m
        
        # å†²çªæ£€æµ‹ï¼ˆåªåœ¨å…¥å£çº§åˆ«ï¼‰
        conflict_targets = self._collect_conflict_targets(matches, guidelines_to_skip, journey_entries)
        
        if len(conflict_targets) >= 2 and self._current_context:
            self._logger.debug(f"ğŸ¤” {len(conflict_targets)} conflicting options detected, using disambiguation batch")
            disambiguation_result = await self._process_disambiguation(conflict_targets)
            
            if disambiguation_result:
                result.append(disambiguation_result)
                if disambiguation_result.metadata.get("disambiguation"):
                    # æ’é™¤æ‰€æœ‰å†²çªç›¸å…³çš„ guidelinesï¼ˆå…¥å£ + nodesï¼‰
                    conflict_ids = {g.id for g in conflict_targets}
                    conflict_journey_ids = set(journey_entries.keys())
                    for m in matches:
                        if m.guideline.id in conflict_ids:
                            guidelines_to_skip.add(m.guideline.id)
                        elif m.metadata.get("step_selection_journey_id") in conflict_journey_ids:
                            guidelines_to_skip.add(m.guideline.id)
                        elif any(t.startswith("journey:") for t in m.guideline.tags):
                            guidelines_to_skip.add(m.guideline.id)
        elif len(journey_entries) == 1:
            # å• Journey æ— å†²çªï¼Œæ’é™¤å…¶ä»– journey ç›¸å…³çš„ guidelines
            journey_id = next(iter(journey_entries.keys()))
            for m in matches:
                if m.guideline.id in guidelines_to_skip:
                    continue
                if not m.guideline.content.action:
                    continue
                # ä¿ç•™å½“å‰ journey çš„ nodes
                if m.metadata.get("step_selection_journey_id") == journey_id:
                    continue
                # ä¿ç•™å½“å‰ journey çš„å…¥å£
                if any(t == f"journey:{journey_id}" for t in m.guideline.tags):
                    continue
                # æ’é™¤å…¶ä»– journey çš„å…¥å£å’Œé journey guidelines
                if any(t.startswith("journey:") for t in m.guideline.tags):
                    guidelines_to_skip.add(m.guideline.id)
                    continue
                # æ’é™¤å…¶ä»–æ™®é€š actionable guidelines
                guidelines_to_skip.add(m.guideline.id)
            self._logger.debug(f"ğŸ¯ Single journey active: {journey_id}")

        result.extend(m for m in matches if m.guideline.id not in guidelines_to_skip)

        return result

    def _create_batches_observational_guideline(
        self,
        guidelines: Sequence[Guideline],
        context: GuidelineMatchingContext,
    ) -> Sequence[GuidelineMatchingBatch]:
        journeys = list(
            chain.from_iterable(
                self._entity_queries.find_journeys_on_which_this_guideline_depends.get(g.id, [])
                for g in guidelines
            )
        )

        batches = []

        guidelines_dict = {g.id: g for g in guidelines}
        batch_size = self._get_optimal_batch_size(guidelines_dict)
        guidelines_list = list(guidelines_dict.items())
        batch_count = math.ceil(len(guidelines_dict) / batch_size)

        for batch_number in range(batch_count):
            start_offset = batch_number * batch_size
            end_offset = start_offset + batch_size
            batch = dict(guidelines_list[start_offset:end_offset])
            batches.append(
                self._create_batch_observational_guideline(
                    guidelines=list(batch.values()),
                    journeys=journeys,
                    context=GuidelineMatchingContext(
                        agent=context.agent,
                        session=context.session,
                        customer=context.customer,
                        context_variables=context.context_variables,
                        interaction_history=context.interaction_history,
                        terms=context.terms,
                        capabilities=context.capabilities,
                        staged_events=context.staged_events,
                        active_journeys=journeys,
                        journey_paths=context.journey_paths,
                    ),
                )
            )

        return batches

    def _create_batch_observational_guideline(
        self,
        guidelines: Sequence[Guideline],
        journeys: Sequence[Journey],
        context: GuidelineMatchingContext,
    ) -> GenericObservationalGuidelineMatchingBatch:
        return GenericObservationalGuidelineMatchingBatch(
            logger=self._logger,
            optimization_policy=self._optimization_policy,
            schematic_generator=self._observational_guideline_schematic_generator,
            guidelines=guidelines,
            journeys=journeys,
            context=context,
        )

    def _create_batches_previously_applied_actionable_guideline(
        self,
        guidelines: Sequence[Guideline],
        context: GuidelineMatchingContext,
    ) -> Sequence[GuidelineMatchingBatch]:
        journeys = list(
            chain.from_iterable(
                self._entity_queries.find_journeys_on_which_this_guideline_depends.get(g.id, [])
                for g in guidelines
            )
        )

        batches = []

        guidelines_dict = {g.id: g for g in guidelines}
        batch_size = self._get_optimal_batch_size(guidelines_dict)
        guidelines_list = list(guidelines_dict.items())
        batch_count = math.ceil(len(guidelines_dict) / batch_size)

        for batch_number in range(batch_count):
            start_offset = batch_number * batch_size
            end_offset = start_offset + batch_size
            batch = dict(guidelines_list[start_offset:end_offset])
            batches.append(
                self._create_batch_previously_applied_actionable_guideline(
                    guidelines=list(batch.values()),
                    journeys=journeys,
                    context=GuidelineMatchingContext(
                        agent=context.agent,
                        session=context.session,
                        customer=context.customer,
                        context_variables=context.context_variables,
                        interaction_history=context.interaction_history,
                        terms=context.terms,
                        capabilities=context.capabilities,
                        staged_events=context.staged_events,
                        active_journeys=journeys,
                        journey_paths=context.journey_paths,
                    ),
                )
            )

        return batches

    def _create_batch_previously_applied_actionable_guideline(
        self,
        guidelines: Sequence[Guideline],
        journeys: Sequence[Journey],
        context: GuidelineMatchingContext,
    ) -> GenericPreviouslyAppliedActionableGuidelineMatchingBatch:
        return GenericPreviouslyAppliedActionableGuidelineMatchingBatch(
            logger=self._logger,
            optimization_policy=self._optimization_policy,
            schematic_generator=self._previously_applied_actionable_guideline_schematic_generator,
            guidelines=guidelines,
            journeys=journeys,
            context=context,
        )

    def _create_batches_previously_applied_actionable_customer_dependent_guideline(
        self,
        guidelines: Sequence[Guideline],
        context: GuidelineMatchingContext,
    ) -> Sequence[GuidelineMatchingBatch]:
        journeys = list(
            chain.from_iterable(
                self._entity_queries.find_journeys_on_which_this_guideline_depends.get(g.id, [])
                for g in guidelines
            )
        )

        batches = []

        guidelines_dict = {g.id: g for g in guidelines}
        batch_size = self._get_optimal_batch_size(guidelines_dict)
        guidelines_list = list(guidelines_dict.items())
        batch_count = math.ceil(len(guidelines_dict) / batch_size)

        for batch_number in range(batch_count):
            start_offset = batch_number * batch_size
            end_offset = start_offset + batch_size
            batch = dict(guidelines_list[start_offset:end_offset])
            batches.append(
                self._create_batch_previously_applied_actionable_customer_dependent_guideline(
                    guidelines=list(batch.values()),
                    journeys=journeys,
                    context=GuidelineMatchingContext(
                        agent=context.agent,
                        session=context.session,
                        customer=context.customer,
                        context_variables=context.context_variables,
                        interaction_history=context.interaction_history,
                        terms=context.terms,
                        capabilities=context.capabilities,
                        staged_events=context.staged_events,
                        active_journeys=journeys,
                        journey_paths=context.journey_paths,
                    ),
                )
            )

        return batches

    def _create_batch_previously_applied_actionable_customer_dependent_guideline(
        self,
        guidelines: Sequence[Guideline],
        journeys: Sequence[Journey],
        context: GuidelineMatchingContext,
    ) -> GenericPreviouslyAppliedActionableCustomerDependentGuidelineMatchingBatch:
        return GenericPreviouslyAppliedActionableCustomerDependentGuidelineMatchingBatch(
            logger=self._logger,
            optimization_policy=self._optimization_policy,
            schematic_generator=self._previously_applied_actionable_customer_dependent_guideline_schematic_generator,
            guidelines=guidelines,
            journeys=journeys,
            context=context,
        )

    def _create_batches_actionable_guideline(
        self,
        guidelines: Sequence[Guideline],
        context: GuidelineMatchingContext,
    ) -> Sequence[GuidelineMatchingBatch]:
        journeys = list(
            chain.from_iterable(
                self._entity_queries.find_journeys_on_which_this_guideline_depends.get(g.id, [])
                for g in guidelines
            )
        )

        batches = []

        guidelines_dict = {g.id: g for g in guidelines}
        batch_size = self._get_optimal_batch_size(guidelines_dict)
        guidelines_list = list(guidelines_dict.items())
        batch_count = math.ceil(len(guidelines_dict) / batch_size)

        for batch_number in range(batch_count):
            start_offset = batch_number * batch_size
            end_offset = start_offset + batch_size
            batch = dict(guidelines_list[start_offset:end_offset])
            batches.append(
                self._create_batch_actionable_guideline(
                    guidelines=list(batch.values()),
                    journeys=journeys,
                    context=GuidelineMatchingContext(
                        agent=context.agent,
                        session=context.session,
                        customer=context.customer,
                        context_variables=context.context_variables,
                        interaction_history=context.interaction_history,
                        terms=context.terms,
                        capabilities=context.capabilities,
                        staged_events=context.staged_events,
                        active_journeys=journeys,
                        journey_paths=context.journey_paths,
                    ),
                )
            )

        return batches

    def _create_batch_actionable_guideline(
        self,
        guidelines: Sequence[Guideline],
        journeys: Sequence[Journey],
        context: GuidelineMatchingContext,
    ) -> GenericActionableGuidelineMatchingBatch:
        return GenericActionableGuidelineMatchingBatch(
            logger=self._logger,
            optimization_policy=self._optimization_policy,
            schematic_generator=self._actionable_guideline_schematic_generator,
            guidelines=guidelines,
            journeys=journeys,
            context=context,
        )

    async def _try_get_disambiguation_group_targets(
        self,
        candidate: Guideline,
        guidelines: Sequence[Guideline],
    ) -> Optional[list[Guideline]]:
        guidelines_dict = {g.id: g for g in guidelines}

        if relationships := await self._relationship_store.list_relationships(
            kind=RelationshipKind.DISAMBIGUATION,
            source_id=candidate.id,
        ):
            targets = [guidelines_dict[cast(GuidelineId, r.target.id)] for r in relationships]

            if len(targets) > 1:
                return targets

        return None

    def _create_batch_disambiguation_guideline(
        self,
        disambiguation_guideline: Guideline,
        disambiguation_targets: list[Guideline],
        context: GuidelineMatchingContext,
    ) -> GenericDisambiguationGuidelineMatchingBatch:
        journeys = list(
            chain.from_iterable(
                self._entity_queries.find_journeys_on_which_this_guideline_depends.get(g.id, [])
                for g in [disambiguation_guideline, *disambiguation_targets]
            )
        )

        return GenericDisambiguationGuidelineMatchingBatch(
            logger=self._logger,
            journey_store=self._journey_store,
            optimization_policy=self._optimization_policy,
            schematic_generator=self._disambiguation_guidelines_schematic_generator,
            disambiguation_guideline=disambiguation_guideline,
            disambiguation_targets=disambiguation_targets,
            context=GuidelineMatchingContext(
                agent=context.agent,
                session=context.session,
                customer=context.customer,
                context_variables=context.context_variables,
                interaction_history=context.interaction_history,
                terms=context.terms,
                capabilities=context.capabilities,
                staged_events=context.staged_events,
                active_journeys=journeys,
                journey_paths=context.journey_paths,
            ),
        )

    async def _create_batch_journey_step_selection(
        self,
        examined_journey: Journey,
        step_guidelines: Sequence[Guideline],
        context: GuidelineMatchingContext,
    ) -> GenericJourneyNodeSelectionBatch:
        return GenericJourneyNodeSelectionBatch(
            logger=self._logger,
            guideline_store=self._guideline_store,
            optimization_policy=self._optimization_policy,
            schematic_generator=self._journey_step_selection_schematic_generator,
            examined_journey=examined_journey,
            context=GuidelineMatchingContext(
                agent=context.agent,
                session=context.session,
                customer=context.customer,
                context_variables=context.context_variables,
                interaction_history=context.interaction_history,
                terms=context.terms,
                capabilities=context.capabilities,
                staged_events=context.staged_events,
                active_journeys=context.active_journeys,
                journey_paths=context.journey_paths,
            ),
            node_guidelines=step_guidelines,
            journey_path=context.journey_paths.get(examined_journey.id, []),
        )

    def _get_optimal_batch_size(self, guidelines: dict[GuidelineId, Guideline]) -> int:
        return self._optimization_policy.get_guideline_matching_batch_size(len(guidelines))

    def _collect_conflict_targets(
        self,
        matches: Sequence[GuidelineMatch],
        guidelines_to_skip: set[GuidelineId],
        journey_entries: dict[str, GuidelineMatch],  # journey_id -> å…¥å£ match
    ) -> list[Guideline]:
        """æ”¶é›†éœ€è¦ç”¨æˆ·æ¾„æ¸…çš„å†²çª targetsï¼ˆåªåœ¨å…¥å£çº§åˆ«ï¼‰
        
        è®¾è®¡åŸåˆ™ï¼š
        - å†²çªæ£€æµ‹åªåœ¨å…¥å£çº§åˆ«è¿›è¡Œ
        - journey nodes æ˜¯æ‰§è¡Œå±‚ï¼Œä¸å‚ä¸å†²çªæ£€æµ‹
        - å…¥å£å’Œ nodes ä¸æ˜¯åŒä¸€ç»´åº¦çš„æ•°æ®
        """
        # å¤š Journey åœºæ™¯ï¼šæ‰€æœ‰ journey å…¥å£éƒ½æ˜¯å†²çª targets
        if len(journey_entries) > 1:
            return [m.guideline for m in journey_entries.values()
                    if m.guideline.id not in guidelines_to_skip]
        
        # å• Journey åœºæ™¯ï¼šæ£€æŸ¥ journey å…¥å£å’Œå…¶ä»– actionable guidelines æ˜¯å¦å†²çª
        if len(journey_entries) == 1:
            journey_match = next(iter(journey_entries.values()))
            journey_score = journey_match.score
            journey_guideline = journey_match.guideline
            
            # æ”¶é›†å…¶ä»–é«˜åˆ† actionable guidelinesï¼ˆæ’é™¤æ‰€æœ‰ journey ç›¸å…³ï¼‰
            other_high_score: list[tuple[Guideline, int]] = []
            for m in matches:
                if m.guideline.id in guidelines_to_skip or not m.guideline.content.action:
                    continue
                # æ’é™¤ journey å…¥å£
                if any(t.startswith("journey:") for t in m.guideline.tags):
                    continue
                # æ’é™¤ journey nodes
                if m.metadata.get("step_selection_journey_id"):
                    continue
                if m.score >= 10:
                    other_high_score.append((m.guideline, m.score))
            
            # å¦‚æœå­˜åœ¨å…¶ä»–é«˜åˆ† guidelines ä¸” score ç›¸è¿‘ï¼Œéœ€è¦æ¾„æ¸…
            if other_high_score and journey_guideline:
                max_other = max(s for _, s in other_high_score)
                if abs(journey_score - max_other) <= 2:
                    return [journey_guideline] + [g for g, _ in other_high_score]
        
        return []

    async def _process_disambiguation(
        self,
        conflict_targets: list[Guideline],
    ) -> GuidelineMatch | None:
        """ä½¿ç”¨disambiguation batchå¤„ç†å†²çªï¼ŒåŒ…å«çŠ¶æ€ç®¡ç†
        
        çŠ¶æ€ç®¡ç†é€»è¾‘ï¼ˆç”±disambiguation batchå¤„ç†ï¼‰ï¼š
        1. å¦‚æœä¹‹å‰å·²è¯·æ±‚æ¾„æ¸…ä¸”ç”¨æˆ·å·²å›ç­” â†’ is_ambiguous=falseï¼Œä¸å†æ¾„æ¸…
        2. å¦‚æœä¹‹å‰å·²è¯·æ±‚æ¾„æ¸…ä½†ç”¨æˆ·æœªå›ç­” â†’ is_ambiguous=trueï¼Œé‡æ–°æ¾„æ¸…
        3. å¦‚æœæ˜¯æ–°çš„æ­§ä¹‰ â†’ is_ambiguous=trueï¼Œè¯·æ±‚æ¾„æ¸…
        """
        if not self._current_context:
            return None
        
        # åˆ›å»ºä¸´æ—¶çš„disambiguation guideline
        temp_guideline = Guideline(
            id=cast(GuidelineId, f"<auto_disambig_{generate_id()}>"),
            creation_utc=datetime.now(),
            content=GuidelineContent(
                condition="Multiple conflicting intents detected",
                action=None,
            ),
            enabled=True,
            tags=[],
            metadata={},
        )
        
        # ä½¿ç”¨ç°æœ‰çš„disambiguation batchï¼ˆåŒ…å«çŠ¶æ€ç®¡ç†ï¼‰
        batch = self._create_batch_disambiguation_guideline(
            disambiguation_guideline=temp_guideline,
            disambiguation_targets=conflict_targets,
            context=self._current_context,
        )
        
        try:
            batch_result = await batch.process()
            if batch_result.matches:
                match = batch_result.matches[0]
                # æ£€æŸ¥disambiguationç»“æœ
                if match.metadata.get("disambiguation"):
                    # éœ€è¦æ¾„æ¸…ï¼šè¿”å›å¸¦æœ‰actionçš„guideline
                    disambiguation_data = cast(dict[str, JSONSerializable], match.metadata["disambiguation"])
                    enriched_action = disambiguation_data.get("enriched_action", "")
                    if enriched_action:
                        self._logger.debug(f"ğŸ¤” Disambiguation needed: {match.rationale}")
                        return GuidelineMatch(
                            guideline=Guideline(
                                id=cast(GuidelineId, f"<disambig_{generate_id()}>"),
                                creation_utc=datetime.now(),
                                content=GuidelineContent(
                                    condition=match.guideline.content.condition,
                                    action=cast(str, enriched_action),
                                ),
                                enabled=True,
                                tags=[],
                                metadata={},
                            ),
                            score=10,
                            rationale=match.rationale,
                            metadata=match.metadata,
                        )
                else:
                    # ä¸éœ€è¦æ¾„æ¸…ï¼ˆç”¨æˆ·å·²å›ç­”æˆ–æ„å›¾æ¸…æ™°ï¼‰
                    self._logger.debug(f"â­ï¸ No disambiguation needed: {match.rationale}")
                    return None
        except Exception as e:
            self._logger.warning(f"Disambiguation batch failed: {e}")
        
        return None
